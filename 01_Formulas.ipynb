{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\udcd8 Forecasting Evaluation Metrics Lab\n", "\n", "This notebook explains **why we need metrics in forecasting**, and how to compute the most common ones: **MSE, RMSE, MAE, and MAPE**.\n", "\n", "We will:\n", "1. Define the error term.\n", "2. Introduce each metric with equations and theory.\n", "3. Compute metrics manually and with **Keras**.\n", "4. Compare results.\n", "5. Show how to integrate them in a Keras model.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Why Do We Need Metrics?\n", "\n", "When we build a forecasting or regression model (e.g., ARIMA, LSTM, Linear Regression), predictions $\\hat{y}_t$ must be compared against actual values $y_t$.\n", "\n", "The error is simply:\n", "\n", "$$\n", "e_t = y_t - \\hat{y}_t\n", "$$\n", "\n", "- $y_t$: actual value at time $t$\n", "- $\\hat{y}_t$: predicted (forecasted) value at time $t$\n", "- $e_t$: error (difference between actual and predicted)\n", "\n", "Errors can be positive or negative, but to **summarize model performance** across many predictions, we need metrics that capture overall error size. These metrics guide us in comparing models and tuning hyperparameters."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Mean Squared Error (MSE)\n", "\n", "**Definition:**\n", "The **Mean Squared Error (MSE)** is the average of the squared differences between actual and predicted values.\n", "\n", "$$\n", "MSE = \\frac{1}{n}\\sum_{t=1}^{n} (y_t - \\hat{y}_t)^2\n", "$$\n", "\n", "**Why use it?**\n", "- Squaring ensures positive and negative errors don\u2019t cancel out.\n", "- Large errors are penalized more heavily.\n", "- Commonly used as a loss function in regression tasks (e.g., training neural networks).\n", "\n", "**In ML domain:**\n", "- Used in optimization (backpropagation minimizes MSE).\n", "- Good when large deviations are very costly.\n", "- Drawback: units are squared, making interpretation harder."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import tensorflow as tf\n", "from tensorflow.keras import backend as K\n", "\n", "# Example data\n", "y_true = np.array([10, 12, 14, 18, 20], dtype=float)\n", "y_pred = np.array([11, 13, 13, 20, 19], dtype=float)\n", "\n", "# Manual MSE\n", "mse_manual = np.mean((y_true - y_pred) ** 2)\n", "\n", "# Keras MSE\n", "mse_keras = K.eval(tf.keras.metrics.mean_squared_error(y_true, y_pred))\n", "\n", "print(\"Manual MSE:\", mse_manual)\n", "print(\"Keras MSE :\", mse_keras)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Root Mean Squared Error (RMSE)\n", "\n", "**Definition:**\n", "The **Root Mean Squared Error (RMSE)** is the square root of the MSE.\n", "\n", "$$\n", "RMSE = \\sqrt{\\frac{1}{n}\\sum_{t=1}^{n} (y_t - \\hat{y}_t)^2}\n", "$$\n", "\n", "**Why use it?**\n", "- Expressed in the same units as the original data, making it easier to interpret than MSE.\n", "- Still penalizes large errors more strongly.\n", "\n", "**In ML domain:**\n", "- Common evaluation metric in forecasting competitions (e.g., Kaggle).\n", "- Helps judge the typical error magnitude.\n", "- Sensitive to outliers."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rmse_manual = np.sqrt(mse_manual)\n", "print(\"Manual RMSE:\", rmse_manual)\n", "\n", "def root_mean_squared_error(y_true, y_pred):\n", "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n", "\n", "rmse_keras = K.eval(root_mean_squared_error(y_true, y_pred))\n", "print(\"Keras RMSE :\", rmse_keras)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. Mean Absolute Error (MAE)\n", "\n", "**Definition:**\n", "The **Mean Absolute Error (MAE)** is the average of absolute differences between actual and predicted values.\n", "\n", "$$\n", "MAE = \\frac{1}{n}\\sum_{t=1}^{n} |y_t - \\hat{y}_t|\n", "$$\n", "\n", "**Why use it?**\n", "- Provides average error magnitude directly.\n", "- Less sensitive to outliers compared to MSE.\n", "- Easier to explain to non-technical stakeholders.\n", "\n", "**In ML domain:**\n", "- Used when all errors are equally important, regardless of size.\n", "- Popular in demand forecasting and regression problems.\n", "- Does not excessively penalize rare large deviations."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mae_manual = np.mean(np.abs(y_true - y_pred))\n", "mae_keras = K.eval(tf.keras.metrics.mean_absolute_error(y_true, y_pred))\n", "\n", "print(\"Manual MAE:\", mae_manual)\n", "print(\"Keras MAE :\", mae_keras)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Mean Absolute Percentage Error (MAPE)\n", "\n", "**Definition:**\n", "The **Mean Absolute Percentage Error (MAPE)** expresses the error as a percentage of actual values.\n", "\n", "$$\n", "MAPE = \\frac{100}{n}\\sum_{t=1}^{n} \\left|\\frac{y_t - \\hat{y}_t}{y_t}\\right|\n", "$$\n", "\n", "**Why use it?**\n", "- Intuitive because it shows relative error in % terms.\n", "- Useful when comparing errors across datasets with different scales.\n", "\n", "**In ML domain:**\n", "- Widely used in business and finance (easy interpretation for managers).\n", "- Problem: becomes unstable when $y_t$ is close to 0.\n", "- Can exaggerate error if actual values are very small."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mape_manual = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n", "mape_keras = K.eval(tf.keras.metrics.mean_absolute_percentage_error(y_true, y_pred))\n", "\n", "print(\"Manual MAPE (%):\", mape_manual)\n", "print(\"Keras MAPE (%) :\", mape_keras)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Comparison of Metrics\n", "\n", "| Metric | Formula | Pros | Cons |\n", "|--------|---------|------|------|\n", "| **MSE** | $\\frac{1}{n}\\sum (y-\\hat{y})^2$ | Penalizes large errors | Hard to interpret (squared units) |\n", "| **RMSE** | $\\sqrt{\\frac{1}{n}\\sum (y-\\hat{y})^2}$ | Same units as data, interpretable | Sensitive to outliers |\n", "| **MAE** | $\\frac{1}{n}\\sum |y-\\hat{y}|$ | Simple, robust to outliers | Less sensitive to big errors |\n", "| **MAPE** | $\\frac{100}{n}\\sum \\left|\\frac{y-\\hat{y}}{y}\\right|$ | Intuitive % error | Problematic if $y \\approx 0$ |"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Keras Integration in a Model\n", "\n", "When training a Keras model, you can specify metrics like this:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = tf.keras.Sequential([\n", "    tf.keras.layers.Dense(10, activation='relu', input_shape=(1,)),\n", "    tf.keras.layers.Dense(1)\n", "])\n", "\n", "model.compile(\n", "    optimizer='adam',\n", "    loss='mse',\n", "    metrics=[\n", "        tf.keras.metrics.MeanSquaredError(name=\"MSE\"),\n", "        tf.keras.metrics.MeanAbsoluteError(name=\"MAE\"),\n", "        tf.keras.metrics.MeanAbsolutePercentageError(name=\"MAPE\"),\n", "        root_mean_squared_error\n", "    ]\n", ")\n", "\n", "model.summary()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 2}